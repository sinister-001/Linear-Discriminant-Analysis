{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c87e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea7ce3",
   "metadata": {},
   "source": [
    "### Read the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf45c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.442149</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669422</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.491736</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.128099</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198347</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.516529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.582645</td>\n",
       "      <td>0.623967</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.714876</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.632231</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.665289</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.351240</td>\n",
       "      <td>0.301653</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334711</td>\n",
       "      <td>0.289256</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.458678</td>\n",
       "      <td>0.487603</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.549587</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.632231</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.669422</td>\n",
       "      <td>0.673554</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.161157</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.214876</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.223140</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.202479</td>\n",
       "      <td>0.276859</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.487603</td>\n",
       "      <td>0.549587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392562</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>0.524793</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.603306</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.516529</td>\n",
       "      <td>0.462810</td>\n",
       "      <td>0.280992</td>\n",
       "      <td>0.252066</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.615702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.301653</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.359504</td>\n",
       "      <td>0.355372</td>\n",
       "      <td>0.384298</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.309917  0.367769  0.417355  0.442149  0.528926  0.607438  0.657025   \n",
       "1    0.454545  0.471074  0.512397  0.557851  0.595041  0.640496  0.681818   \n",
       "2    0.318182  0.400826  0.491736  0.528926  0.586777  0.657025  0.681818   \n",
       "3    0.198347  0.194215  0.194215  0.194215  0.190083  0.190083  0.243802   \n",
       "4    0.500000  0.545455  0.582645  0.623967  0.648760  0.690083  0.694215   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  0.400826  0.495868  0.570248  0.632231  0.648760  0.640496  0.661157   \n",
       "396  0.367769  0.367769  0.351240  0.301653  0.247934  0.247934  0.367769   \n",
       "397  0.500000  0.533058  0.607438  0.628099  0.657025  0.632231  0.657025   \n",
       "398  0.214876  0.219008  0.219008  0.223140  0.210744  0.202479  0.276859   \n",
       "399  0.516529  0.462810  0.280992  0.252066  0.247934  0.367769  0.574380   \n",
       "\n",
       "            7         8         9  ...      4087      4088      4089  \\\n",
       "0    0.677686  0.690083  0.685950  ...  0.669422  0.652893  0.661157   \n",
       "1    0.702479  0.710744  0.702479  ...  0.157025  0.136364  0.148760   \n",
       "2    0.685950  0.702479  0.698347  ...  0.132231  0.181818  0.136364   \n",
       "3    0.404959  0.483471  0.516529  ...  0.636364  0.657025  0.685950   \n",
       "4    0.714876  0.723140  0.731405  ...  0.161157  0.177686  0.173554   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "395  0.636364  0.665289  0.698347  ...  0.396694  0.264463  0.099174   \n",
       "396  0.512397  0.574380  0.628099  ...  0.334711  0.289256  0.285124   \n",
       "397  0.669422  0.673554  0.702479  ...  0.148760  0.152893  0.161157   \n",
       "398  0.400826  0.487603  0.549587  ...  0.392562  0.367769  0.409091   \n",
       "399  0.615702  0.661157  0.615702  ...  0.264463  0.293388  0.301653   \n",
       "\n",
       "         4090      4091      4092      4093      4094      4095  target  \n",
       "0    0.475207  0.132231  0.148760  0.152893  0.161157  0.157025       0  \n",
       "1    0.152893  0.152893  0.152893  0.152893  0.152893  0.152893       0  \n",
       "2    0.128099  0.148760  0.144628  0.140496  0.148760  0.152893       0  \n",
       "3    0.727273  0.743802  0.764463  0.752066  0.752066  0.739669       0  \n",
       "4    0.177686  0.177686  0.177686  0.177686  0.173554  0.173554       0  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "395  0.181818  0.243802  0.247934  0.161157  0.157025  0.136364      39  \n",
       "396  0.338843  0.404959  0.458678  0.487603  0.512397  0.549587      39  \n",
       "397  0.161157  0.173554  0.157025  0.177686  0.148760  0.190083      39  \n",
       "398  0.479339  0.524793  0.545455  0.574380  0.590909  0.603306      39  \n",
       "399  0.293388  0.322314  0.322314  0.359504  0.355372  0.384298      39  \n",
       "\n",
       "[400 rows x 4097 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('face.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2dab7",
   "metadata": {},
   "source": [
    "### Divide the features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9acca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis = 1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3ef3f",
   "metadata": {},
   "source": [
    "### Define the final required dimension count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ee63656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of dimensions (d) and the desired reduced dimensionality (d')\n",
    "d = X.shape[1]  # 128 dimensions\n",
    "d_prime = 123 # You can change this value based on your requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3bc6e",
   "metadata": {},
   "source": [
    "### Seperate the data into train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a2c5310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ecdf105",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc7c03",
   "metadata": {},
   "source": [
    "### Compute Mean Vectors for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51b92521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.34238489, 0.36953956, 0.3996458 , ..., 0.32408501, 0.32762693,\n",
       "        0.32467533]),\n",
       " array([0.62258954, 0.64508725, 0.67860424, ..., 0.13452709, 0.11248852,\n",
       "        0.10927456]),\n",
       " array([0.40436836, 0.42384888, 0.4557261 , ..., 0.26033058, 0.24498229,\n",
       "        0.24380165]),\n",
       " array([0.45919422, 0.48037191, 0.47055786, ..., 0.30785124, 0.28822314,\n",
       "        0.2732438 ]),\n",
       " array([0.52324382, 0.53254134, 0.57024796, ..., 0.42252066, 0.40650827,\n",
       "        0.40082645]),\n",
       " array([0.57024792, 0.59142562, 0.63326448, ..., 0.65754132, 0.6089876 ,\n",
       "        0.59349173]),\n",
       " array([0.23507805, 0.25344353, 0.31359045, ..., 0.33103764, 0.27731864,\n",
       "        0.24839302]),\n",
       " array([0.42097108, 0.45661156, 0.51033057, ..., 0.23708677, 0.25      ,\n",
       "        0.25516529]),\n",
       " array([0.3989899 , 0.4164371 , 0.43709826, ..., 0.33884297, 0.35261707,\n",
       "        0.3516988 ]),\n",
       " array([0.43270367, 0.51948051, 0.56965763, ..., 0.09504132, 0.11570248,\n",
       "        0.12396694]),\n",
       " array([0.35261708, 0.38360882, 0.50413223, ..., 0.12878788, 0.11983471,\n",
       "        0.11363636]),\n",
       " array([0.49655647, 0.56749311, 0.62878788, ..., 0.11983471, 0.11914601,\n",
       "        0.12190082]),\n",
       " array([0.42470156, 0.45041323, 0.4687787 , ..., 0.38200184, 0.41000918,\n",
       "        0.38429752]),\n",
       " array([0.52715466, 0.55726094, 0.60094452, ..., 0.10625738, 0.08323495,\n",
       "        0.08618654]),\n",
       " array([0.54493801, 0.55991737, 0.56714875, ..., 0.42303719, 0.36673554,\n",
       "        0.32902893]),\n",
       " array([0.46044865, 0.50708383, 0.53069657, ..., 0.32821724, 0.27567886,\n",
       "        0.27154663]),\n",
       " array([0.32479339, 0.37603306, 0.41942149, ..., 0.40991736, 0.36322314,\n",
       "        0.33099174]),\n",
       " array([0.45867769, 0.46198348, 0.46694215, ..., 0.32396694, 0.27603306,\n",
       "        0.2909091 ]),\n",
       " array([0.33195592, 0.44628099, 0.57988981, ..., 0.13774105, 0.14256198,\n",
       "        0.14876033]),\n",
       " array([0.33780992, 0.39411158, 0.45299586, ..., 0.35640496, 0.3197314 ,\n",
       "        0.30320247]),\n",
       " array([0.38337925, 0.42607898, 0.46602388, ..., 0.41873279, 0.44168963,\n",
       "        0.45821855]),\n",
       " array([0.16580578, 0.19008264, 0.24276859, ..., 0.27221075, 0.2660124 ,\n",
       "        0.21797521]),\n",
       " array([0.42561984, 0.4535124 , 0.50154959, ..., 0.31818182, 0.3197314 ,\n",
       "        0.31714876]),\n",
       " array([0.26652893, 0.30578512, 0.3553719 , ..., 0.41322314, 0.39721076,\n",
       "        0.37758265]),\n",
       " array([0.48701298, 0.53305787, 0.59563164, ..., 0.37839433, 0.35360094,\n",
       "        0.36953955]),\n",
       " array([0.60979929, 0.63872492, 0.64757969, ..., 0.22491146, 0.23081464,\n",
       "        0.24557261]),\n",
       " array([0.46115703, 0.55041322, 0.65454546, ..., 0.12561983, 0.14710744,\n",
       "        0.1661157 ]),\n",
       " array([0.58729339, 0.61105373, 0.67252066, ..., 0.18698347, 0.20661157,\n",
       "        0.21022728]),\n",
       " array([0.28650138, 0.25849403, 0.21166207, ..., 0.31037649, 0.31726354,\n",
       "        0.31129476]),\n",
       " array([0.40436835, 0.45985833, 0.5       , ..., 0.44214875, 0.42030697,\n",
       "        0.39787486]),\n",
       " array([0.58057851, 0.63429753, 0.65289256, ..., 0.40547521, 0.45557852,\n",
       "        0.5552686 ]),\n",
       " array([0.50275482, 0.58585858, 0.65656566, ..., 0.1707989 , 0.17033976,\n",
       "        0.18640955]),\n",
       " array([0.13326446, 0.12396694, 0.11673554, ..., 0.62086777, 0.57954544,\n",
       "        0.55785124]),\n",
       " array([0.45385675, 0.46212121, 0.46900826, ..., 0.54063361, 0.55509641,\n",
       "        0.51721763]),\n",
       " array([0.35330579, 0.35192837, 0.34848485, ..., 0.62672178, 0.62327824,\n",
       "        0.59573003]),\n",
       " array([0.25114784, 0.30303031, 0.38062443, ..., 0.43067035, 0.36822773,\n",
       "        0.39072543]),\n",
       " array([0.30619834, 0.26528926, 0.38347108, ..., 0.23099174, 0.26570248,\n",
       "        0.28636364]),\n",
       " array([0.14416896, 0.19605142, 0.27731864, ..., 0.3016529 , 0.26905417,\n",
       "        0.315427  ]),\n",
       " array([0.27823691, 0.26951332, 0.27961432, ..., 0.24655648, 0.25711662,\n",
       "        0.25987144]),\n",
       " array([0.41890496, 0.43595042, 0.4230372 , ..., 0.32644628, 0.32592975,\n",
       "        0.34659091])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_means = []\n",
    "for class_label in range(40):\n",
    "    mean_class = np.mean(X_train[y_train == class_label, :], axis=0)\n",
    "    class_means.append(mean_class)\n",
    "class_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af5828",
   "metadata": {},
   "source": [
    "### Within Class Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c18266b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_W = np.zeros((d, d))  # Initialize the within-class scatter matrix\n",
    "\n",
    "for class_label, mean_class in enumerate(class_means):\n",
    "    scatter_class = np.zeros((d, d))\n",
    "    class_samples = X_train[y_train == class_label]\n",
    "\n",
    "    for x in class_samples:\n",
    "        x_minus_mean = x - mean_class\n",
    "        scatter_class += np.outer(x_minus_mean, x_minus_mean)\n",
    "\n",
    "    S_W += scatter_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fdc3644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.52177666,  5.23619723,  4.31917069, ..., -0.79170999,\n",
       "        -0.82734918, -0.67134082],\n",
       "       [ 5.23619723,  5.67692287,  5.13950313, ..., -1.15154156,\n",
       "        -1.0586106 , -0.89364125],\n",
       "       [ 4.31917069,  5.13950313,  5.89595879, ..., -1.49365327,\n",
       "        -1.34293714, -1.21662807],\n",
       "       ...,\n",
       "       [-0.79170999, -1.15154156, -1.49365327, ...,  5.90185227,\n",
       "         4.851215  ,  4.08599263],\n",
       "       [-0.82734918, -1.0586106 , -1.34293714, ...,  4.851215  ,\n",
       "         5.44230423,  4.9174225 ],\n",
       "       [-0.67134082, -0.89364125, -1.21662807, ...,  4.08599263,\n",
       "         4.9174225 ,  5.26384662]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a4446",
   "metadata": {},
   "source": [
    "### Between Class Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28217e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_overall = np.mean(X_train, axis=0)\n",
    "S_B = np.zeros((d, d))  # Initialize the between-class scatter matrix\n",
    "\n",
    "for class_label, mean_class in enumerate(class_means):\n",
    "    count_class = len(X_train[y_train == class_label])\n",
    "    mean_minus_overall = mean_class - mean_overall\n",
    "    scatter_class = count_class * np.outer(mean_minus_overall, mean_minus_overall)\n",
    "    S_B += scatter_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1a89f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.99012472,  5.19326258,  5.00899934, ..., -1.07224146,\n",
       "        -0.86173412, -0.65525069],\n",
       "       [ 5.19326258,  5.70055755,  5.69466884, ..., -1.5067041 ,\n",
       "        -1.2959715 , -1.03080143],\n",
       "       [ 5.00899934,  5.69466884,  6.13641619, ..., -2.19310874,\n",
       "        -1.95521764, -1.6280637 ],\n",
       "       ...,\n",
       "       [-1.07224146, -1.5067041 , -2.19310874, ...,  5.9036222 ,\n",
       "         5.48182075,  5.18168509],\n",
       "       [-0.86173412, -1.2959715 , -1.95521764, ...,  5.48182075,\n",
       "         5.31850365,  5.10642768],\n",
       "       [-0.65525069, -1.03080143, -1.6280637 , ...,  5.18168509,\n",
       "         5.10642768,  5.1047885 ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f3cff",
   "metadata": {},
   "source": [
    "### Eigen Values and Eigen Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "483c625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "\n",
    "# Sort the eigenvalues and eigenvectors\n",
    "eigen_pairs = [(eigenvalues[i], eigenvectors[:, i]) for i in range(len(eigenvalues))]\n",
    "eigen_pairs = sorted(eigen_pairs, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Choose the top d' eigenvectors and create the transformation matrix W\n",
    "W = np.array([eigen_pair[1] for eigen_pair in eigen_pairs[:d_prime]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d6c2c1",
   "metadata": {},
   "source": [
    "### Get the final dataframe with d' dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a9bf3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the data onto the reduced-dimensional space\n",
    "X_train_lda = X_train.dot(W)\n",
    "X_test_lda = X_test.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "425475e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04765798+0.02610457j,  0.04765798-0.02610457j,\n",
       "        -0.04285459+0.01391231j, ...,  0.08226804+0.00902948j,\n",
       "         0.08226804-0.00902948j, -0.01518085+0.07426844j],\n",
       "       [ 0.04990537+0.0359784j ,  0.04990537-0.0359784j ,\n",
       "        -0.04938392+0.00989909j, ...,  0.04275148+0.0421957j ,\n",
       "         0.04275148-0.0421957j , -0.03013558+0.11980068j],\n",
       "       [ 0.00529888+0.00651607j,  0.00529888-0.00651607j,\n",
       "        -0.04002194+0.03432614j, ...,  0.051594  +0.09025391j,\n",
       "         0.051594  -0.09025391j, -0.04587822+0.12546701j],\n",
       "       ...,\n",
       "       [ 0.06480595+0.02460348j,  0.06480595-0.02460348j,\n",
       "        -0.03693622+0.00611584j, ...,  0.08041942-0.00444794j,\n",
       "         0.08041942+0.00444794j,  0.02970637+0.0774124j ],\n",
       "       [ 0.02987141+0.02934122j,  0.02987141-0.02934122j,\n",
       "        -0.05746182+0.01120071j, ...,  0.01062791-0.06852716j,\n",
       "         0.01062791+0.06852716j, -0.01428296-0.01882141j],\n",
       "       [-0.00264474+0.00737973j, -0.00264474-0.00737973j,\n",
       "        -0.05823055+0.01725261j, ...,  0.10615514+0.03914635j,\n",
       "         0.10615514-0.03914635j, -0.02918879+0.12748501j]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aae9e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06038572+0.01529328j,  0.06038572-0.01529328j,\n",
       "         0.00154758+0.00712971j, ...,  0.06848456+0.04294506j,\n",
       "         0.06848456-0.04294506j, -0.02008284+0.08070894j],\n",
       "       [-0.03008137+0.03287601j, -0.03008137-0.03287601j,\n",
       "        -0.04779836+0.07229391j, ...,  0.11346198+0.07484227j,\n",
       "         0.11346198-0.07484227j, -0.03378676+0.12091439j],\n",
       "       [ 0.0755044 -0.00387688j,  0.0755044 +0.00387688j,\n",
       "        -0.03038024+0.0045076j , ...,  0.12613279-0.07155914j,\n",
       "         0.12613279+0.07155914j,  0.00903928+0.01716969j],\n",
       "       ...,\n",
       "       [ 0.06108131+0.02381683j,  0.06108131-0.02381683j,\n",
       "        -0.02669957+0.02865511j, ...,  0.05265464+0.1023625j ,\n",
       "         0.05265464-0.1023625j , -0.08457658+0.11829983j],\n",
       "       [ 0.03880013+0.03884968j,  0.03880013-0.03884968j,\n",
       "        -0.07099539+0.04583249j, ..., -0.00779311-0.02292228j,\n",
       "        -0.00779311+0.02292228j, -0.06736094+0.06418937j],\n",
       "       [ 0.08475896+0.04539482j,  0.08475896-0.04539482j,\n",
       "        -0.06252963+0.02263021j, ...,  0.00512259+0.05733855j,\n",
       "         0.00512259-0.05733855j, -0.05347306+0.0977826j ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f8254e",
   "metadata": {},
   "source": [
    "### We will be using KNN Classifier for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a9a79e",
   "metadata": {},
   "source": [
    "#### Euclidean Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8ce5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(X_train, X_test):\n",
    "    all_point_distances = []\n",
    "    for i in X_test:\n",
    "        point_distance = []\n",
    "        for j in X_train:\n",
    "            dist = np.sqrt(np.sum((j-i)**2))\n",
    "            point_distance.append(dist)\n",
    "        all_point_distances.append(point_distance)\n",
    "    arr = np.array(all_point_distances)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bdaf2c",
   "metadata": {},
   "source": [
    "#### KNN Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ba43f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(distance_array, y_train, k):\n",
    "    array_indexes = []\n",
    "    for point in distance_array:\n",
    "        nearest_points = np.argsort(point)[:k]\n",
    "        array_indexes.append(nearest_points)\n",
    "    array_indexes = np.array(array_indexes)\n",
    "    \n",
    "    y_values = []\n",
    "    for point in array_indexes:\n",
    "        values = []\n",
    "        for i in point:\n",
    "            values.append(y_train[i])\n",
    "        y_values.append(values)\n",
    "    y_pred = []\n",
    "    for point in y_values:\n",
    "        y_pred.append(max(point, key = point.count))\n",
    "    y_pred = np.array(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7e3e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(y_pred, y_test):\n",
    "    return (np.sum(y_pred == y_test) / len(y_test))*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac6117bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Output: [15 28 18 11 27 18 10 10 30 31 25  2 15 13 11 18 24 30 37  9 10 25 10  4\n",
      " 34  2 24  6 23 33  3  5 14  1 32 18 33  2 29 11 11 34 15 38 32 33 13 25\n",
      "  4 12 39 21 35 39  5  0 29 13 19  0 22 34 29  3 21 22  0 23 14  7 19  9\n",
      " 24 34 20 27 33  9  7  8]\n",
      "Predicted Output: [ 8  6 18 33 35 30 12 35 13  3 23 37  6 18 10 19  9 24 35 36 12 12 17  3\n",
      " 16  1 30 26 31  5  2 27 14 18 38 19  3 33 30 33 23 16  4  9  4 30 37 35\n",
      " 32  2 34  3 28  4 27  7 30  3 14 33  3 24 30 16  8  3 13  3 37 24 31  2\n",
      " 26 17 36 26  3 19  3  1]\n"
     ]
    }
   ],
   "source": [
    "eud = euclidean(X_train_lda, X_test_lda)\n",
    "k = 3\n",
    "y_pred = knn_classify(eud, y_train, k)\n",
    "print(f\"Actual Output: {y_test}\\nPredicted Output: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "860b4db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=3 : 25.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy with k={k} : {check_accuracy(y_pred, y_test)*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
